# src/sponsr.py
"""–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–ª—è Sponsr.ru"""

import json
import re

from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup
import html2text

from .config import Config, Source, load_cookie
from .database import Database
from .downloader import BaseDownloader, Post, retry_request

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è embed URL –≤–∏–¥–µ–æ—Ö–æ—Å—Ç–∏–Ω–≥–æ–≤ (whitelist).
# –ï—Å–ª–∏ iframe src –º–∞—Ç—á–∏—Ç –æ–¥–∏–Ω –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ ‚Äî —ç—Ç–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ.
VIDEO_EMBED_PATTERNS = [
    r'rutube\.ru/play/embed/',
    r'youtube\.com/embed/',
    r'player\.vimeo\.com/video/',
    r'ok\.ru/videoembed/',
    r'vk\.com/video_ext\.php',
]


class SponsorDownloader(BaseDownloader):
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ —Å—Ç–∞—Ç–µ–π —Å Sponsr.ru"""

    PLATFORM = "sponsr"
    FETCH_FULL_POST_IN_SYNC = True

    def __init__(self, config: Config, source: Source, db: Database):
        self._project_id: str | None = None
        super().__init__(config, source, db)

    def _setup_session(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Å—Å–∏–∏ —Å cookies."""
        cookie = load_cookie(self.config.auth.sponsr_cookie_file)
        self.session.headers.update({
            'Cookie': cookie,
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'X-Requested-With': 'XMLHttpRequest',
        })

    def _get_project_id(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç project_id —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–µ–∫—Ç–∞."""
        if self._project_id:
            return self._project_id

        url = f"https://sponsr.ru/{self.source.author}/"
        def do_request():
            resp = self.session.get(url, timeout=self.TIMEOUT)
            resp.raise_for_status()
            return resp

        response = retry_request(do_request, max_retries=3)

        soup = BeautifulSoup(response.text, 'lxml')
        data_tag = soup.find('script', id='__NEXT_DATA__')
        if not data_tag:
            raise ValueError(f"–ù–µ –Ω–∞–π–¥–µ–Ω __NEXT_DATA__ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {url}")

        data = json.loads(data_tag.string)
        project_id = data.get('props', {}).get('pageProps', {}).get('project', {}).get('id')
        if not project_id:
            raise ValueError(f"–ù–µ –Ω–∞–π–¥–µ–Ω project.id –≤ __NEXT_DATA__")

        self._project_id = str(project_id)
        return self._project_id

    def fetch_posts_list(
        self,
        existing_ids: set[str] | None = None,
        incremental: bool = False,
        safety_chunks: int = 1
    ) -> list[dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ API.
        
        Args:
            existing_ids: –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö post_id (–¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞)
            incremental: –í–∫–ª—é—á–∏—Ç—å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º
            safety_chunks: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ "–∑–∞—â–∏—Ç–Ω—ã—Ö" —á–∞–Ω–∫–æ–≤ –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π
        """
        project_id = self._get_project_id()
        all_posts = []
        offset = 0
        clean_chunks_count = 0  # –°—á—ë—Ç—á–∏–∫ "—á–∏—Å—Ç—ã—Ö" —á–∞–Ω–∫–æ–≤

        while True:
            api_url = f"https://sponsr.ru/project/{project_id}/more-posts/?offset={offset}"
            def do_request():
                resp = self.session.get(api_url, timeout=self.TIMEOUT)
                resp.raise_for_status()
                return resp

            response = retry_request(do_request, max_retries=3)

            data = response.json().get("response", {})
            posts_chunk = data.get("rows", [])

            if not posts_chunk:
                break

            all_posts.extend(posts_chunk)
            offset = len(all_posts)

            total = data.get("rows_count", 0)

            # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º: –ø—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –ø–æ—Å—Ç—ã —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
            if incremental and existing_ids is not None:
                chunk_ids = {str(p.get('post_id')) for p in posts_chunk}
                all_existing = chunk_ids.issubset(existing_ids)

                if all_existing:
                    clean_chunks_count += 1
                    print(f"  –ü–æ–ª—É—á–µ–Ω–æ {offset}/{total} –ø–æ—Å—Ç–æ–≤... (—á–∞–Ω–∫ —É–∂–µ —Å–∫–∞—á–∞–Ω)")
                    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –ø–æ—Å–ª–µ safety_chunks + 1 (–ø–µ—Ä–≤—ã–π —á–∏—Å—Ç—ã–π + N –∑–∞—â–∏—Ç–Ω—ã—Ö)
                    if clean_chunks_count > safety_chunks:
                        print(f"  ‚ö° –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –Ω–∞ {offset} –ø–æ—Å—Ç–∞—Ö (–≤—Å–µ –Ω–æ–≤—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã)")
                        break
                else:
                    clean_chunks_count = 0
                    print(f"  –ü–æ–ª—É—á–µ–Ω–æ {offset}/{total} –ø–æ—Å—Ç–æ–≤...")
            else:
                print(f"  –ü–æ–ª—É—á–µ–Ω–æ {offset}/{total} –ø–æ—Å—Ç–æ–≤...")

        return all_posts

    def fetch_post(self, post_id: str) -> Post | None:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–¥–∏–Ω –ø–æ—Å—Ç –ø–æ ID."""
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–ø—Ä—è–º—É—é —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ—Å—Ç–∞
        post = self._fetch_post_from_page(post_id)
        if post:
            return post

        # Fallback: –∏—â–µ–º –≤ API –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ (–±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ–≥–æ —Å–ø–∏—Å–∫–∞)
        return self._find_post_in_api(post_id)

    def _fetch_post_from_page(self, post_id: str) -> Post | None:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å—Ç –Ω–∞–ø—Ä—è–º—É—é —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        # URL —Ñ–æ—Ä–º–∞—Ç: https://sponsr.ru/{author}/{post_id}/...
        url = f"https://sponsr.ru/{self.source.author}/{post_id}/"
        try:
            def do_request():
                resp = self.session.get(url, timeout=self.TIMEOUT)
                resp.raise_for_status()
                return resp

            response = retry_request(do_request, max_retries=3)

            soup = BeautifulSoup(response.text, 'lxml')
            data_tag = soup.find('script', id='__NEXT_DATA__')
            if not data_tag:
                return None

            data = json.loads(data_tag.string)
            post_data = data.get('props', {}).get('pageProps', {}).get('post')
            if not post_data:
                return None

            return self._parse_post(post_data)
        except requests.RequestException:
            return None

    def _find_post_in_api(self, post_id: str) -> Post | None:
        """–ò—â–µ—Ç –ø–æ—Å—Ç –≤ API –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ (–æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–∏)."""
        project_id = self._get_project_id()
        offset = 0

        while True:
            api_url = f"https://sponsr.ru/project/{project_id}/more-posts/?offset={offset}"
            try:
                def do_request():
                    resp = self.session.get(api_url, timeout=self.TIMEOUT)
                    resp.raise_for_status()
                    return resp

                response = retry_request(do_request, max_retries=3)

                data = response.json().get("response", {})
                posts_chunk = data.get("rows", [])

                if not posts_chunk:
                    break

                for raw_post in posts_chunk:
                    if str(raw_post.get('post_id')) == post_id:
                        return self._parse_post(raw_post)

                offset += len(posts_chunk)
            except requests.RequestException:
                break

        return None

    def _parse_post(self, raw_data: dict) -> Post:
        """–ü–∞—Ä—Å–∏—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ API –≤ Post."""
        post_id = str(raw_data.get('post_id') or raw_data.get('id'))
        title = raw_data.get('post_title') or raw_data.get('title') or '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
        post_date = raw_data.get('post_date') or raw_data.get('date') or ''

        # URL –ø–æ—Å—Ç–∞
        post_url = raw_data.get('post_url') or f"/{self.source.author}/{post_id}/"
        if post_url and not post_url.startswith('http'):
            post_url = f"https://sponsr.ru{post_url}"

        # HTML –∫–æ–Ω—Ç–µ–Ω—Ç
        content_obj = raw_data.get('post_text') or raw_data.get('text')
        if isinstance(content_obj, dict):
            content_html = content_obj.get('text', '')
        elif isinstance(content_obj, str):
            content_html = content_obj
        else:
            content_html = ''

        # –¢–µ–≥–∏ - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–º–µ–Ω–∞ –∏–∑ –æ–±—ä–µ–∫—Ç–æ–≤
        tags_raw = raw_data.get('tags', [])
        tags = []
        if isinstance(tags_raw, list):
            for tag in tags_raw:
                if isinstance(tag, dict):
                    # API –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª–µ–º tag_name –∏–ª–∏ tag.tag_name
                    tag_name = tag.get('tag_name') or tag.get('tag', {}).get('tag_name')
                    if tag_name:
                        tags.append(tag_name)
                elif isinstance(tag, str):
                    tags.append(tag)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º assets –∏–∑ HTML
        assets = self._extract_assets(content_html)

        return Post(
            post_id=post_id,
            title=title,
            content_html=content_html,
            post_date=post_date,
            source_url=post_url,
            tags=tags,
            assets=assets,
        )

    def _extract_assets(self, html_content: str) -> list[dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ HTML."""
        if not html_content:
            return []

        assets = []
        soup = BeautifulSoup(html_content, 'lxml')

        for img in soup.find_all('img'):
            src = img.get('src') or img.get('data-src')
            if not src:
                continue

            # –ê–±—Å–æ–ª—é—Ç–Ω—ã–π URL
            if not src.startswith('http'):
                src = urljoin('https://sponsr.ru', src)

            # Alt —Ç–µ–∫—Å—Ç
            alt = img.get('alt', '')
            if not alt:
                parent = img.find_parent('div', class_='post-image')
                if parent and parent.get('data-alt'):
                    alt = parent.get('data-alt')

            assets.append({'url': src, 'alt': alt})

        return assets

    def _is_video_embed(self, src: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL embed-—Å—Å—ã–ª–∫–æ–π –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤–∏–¥–µ–æ—Ö–æ—Å—Ç–∏–Ω–≥."""
        for pattern in VIDEO_EMBED_PATTERNS:
            if re.search(pattern, src):
                return True
        return False

    def _replace_video_embeds(self, html_content: str) -> str:
        """–ó–∞–º–µ–Ω—è–µ—Ç iframe/embed –≤–∏–¥–µ–æ –Ω–∞ HTML-—Å—Å—ã–ª–∫–∏.
        
        –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –≤–∏–¥–µ–æ—Ö–æ—Å—Ç–∏–Ω–≥–∏ ‚Üí <a href="embed_url">üìπ –í–∏–¥–µ–æ</a>
        (html2text –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç –≤ markdown-—Å—Å—ã–ª–∫—É, Hugo render hook ‚Äî –≤ iframe).
        –ù–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ ‚Üí —Ç–µ–∫—Å—Ç–æ–≤–∞—è —Å—Å—ã–ª–∫–∞ –∫–∞–∫ fallback.
        """
        soup = BeautifulSoup(html_content, 'lxml')

        for iframe in soup.find_all(['iframe', 'embed']):
            src = iframe.get('src', '')
            if not src:
                continue

            if self._is_video_embed(src):
                # –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π –≤–∏–¥–µ–æ—Ö–æ—Å—Ç–∏–Ω–≥ ‚Üí —Å—Å—ã–ª–∫–∞ —Å embed URL
                link = soup.new_tag('a', href=src)
                link.string = '\U0001f4f9 –í–∏–¥–µ–æ'
                wrapper = soup.new_tag('p')
                wrapper.append(link)
                iframe.replace_with(wrapper)
            elif 'video' in src or 'embed' in src:
                # –ù–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π, –Ω–æ –ø–æ—Ö–æ–∂ –Ω–∞ –≤–∏–¥–µ–æ ‚Üí —Ç–µ–∫—Å—Ç–æ–≤–∞—è —Å—Å—ã–ª–∫–∞
                link = soup.new_tag('a', href=src)
                link.string = '\U0001f4f9 –í–∏–¥–µ–æ'
                wrapper = soup.new_tag('p')
                wrapper.append(link)
                iframe.replace_with(wrapper)

        return str(soup)

    def _cleanup_html(self, html: str) -> str:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ HTML –ø–µ—Ä–µ–¥ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π –≤ Markdown."""
        from bs4 import BeautifulSoup, NavigableString
        
        soup = BeautifulSoup(html, 'lxml')
        
        # 1. –°–ª–∏—è–Ω–∏–µ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Ç–µ–≥–æ–≤: <em><em>text</em></em> ‚Üí <em>text</em>
        #    –¢–∞–∫–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç—ã: <b><strong>, <em><i> –∏ —Ç.–ø.
        equivalent_tags = {'b': 'strong', 'strong': 'b', 'em': 'i', 'i': 'em'}
        for tag in list(soup.find_all(['b', 'strong', 'em', 'i'])):
            if tag.parent is None:
                continue
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: —Ç–µ–≥ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω –¥–æ—á–µ—Ä–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç —Ç–æ–≥–æ –∂–µ —Ç–∏–ø–∞
            children = list(tag.children)
            if len(children) == 1 and hasattr(children[0], 'name'):
                child = children[0]
                equiv = equivalent_tags.get(tag.name)
                if child.name == tag.name or child.name == equiv:
                    # –†–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ç–µ–≥, –æ—Å—Ç–∞–≤–ª—è—è –≤–Ω–µ—à–Ω–∏–π
                    child.unwrap()
        
        # 2. –°–ª–∏—è–Ω–∏–µ —Å–æ—Å–µ–¥–Ω–∏—Ö <em>/<i> —Ç–µ–≥–æ–≤ –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è.
        #    <em>–≤—ã</em> <b><em>–æ–±—è–∑–∞–Ω—ã</em></b> <em>—ç—Ç–æ</em>
        #    ‚Üí <em>–≤—ã <b>–æ–±—è–∑–∞–Ω—ã</b> —ç—Ç–æ</em>
        #    –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫—É—Ä—Å–∏–≤ –ø–æ—Å–ª–µ html2text.
        em_tags = {'em', 'i'}
        bold_tags = {'b', 'strong'}
        self._merge_adjacent_em(soup, em_tags, bold_tags)
        
        # 3. –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–≥–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—ã–Ω–æ—Å–∏–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞—Ä—É–∂—É
        for tag in list(soup.find_all(['b', 'strong', 'em', 'i'])):
            if tag.parent is None:
                continue
            text = tag.get_text()
            if not text:
                tag.decompose()
            elif text.isspace():
                tag.replace_with(text)
            else:
                # –í—ã–Ω–æ—Å leading –ø—Ä–æ–±–µ–ª–æ–≤ –∏–∑ —Ç–µ–≥–∞ –Ω–∞—Ä—É–∂—É (–ø–µ—Ä–µ–¥ —Ç–µ–≥–æ–º)
                first_text = self._first_navigable_string(tag)
                if first_text is not None and first_text.lstrip() != first_text:
                    leading = first_text[:len(first_text) - len(first_text.lstrip())]
                    first_text.replace_with(first_text.lstrip())
                    tag.insert_before(NavigableString(leading))
                
                # –í—ã–Ω–æ—Å trailing –ø—Ä–æ–±–µ–ª–æ–≤ –∏–∑ —Ç–µ–≥–∞ –Ω–∞—Ä—É–∂—É (–ø–æ—Å–ª–µ —Ç–µ–≥–∞)
                last_text = self._last_navigable_string(tag)
                if last_text is not None and last_text.rstrip() != last_text:
                    trailing = last_text[len(last_text.rstrip()):]
                    last_text.replace_with(last_text.rstrip())
                    tag.insert_after(NavigableString(trailing))
        
        # 4. –í—ã–Ω–æ—Å trailing/leading –ø—Ä–æ–±–µ–ª–æ–≤ –∏–∑ <a> —Ç–µ–≥–æ–≤ –Ω–∞—Ä—É–∂—É
        for tag in list(soup.find_all('a')):
            if tag.parent is None:
                continue
            children = list(tag.children)
            if children:
                last_child = children[-1]
                if isinstance(last_child, NavigableString) and last_child != last_child.rstrip():
                    trailing = str(last_child)[len(str(last_child).rstrip()):]
                    last_child.replace_with(NavigableString(str(last_child).rstrip()))
                    tag.insert_after(NavigableString(trailing))
        
        # 5. –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ markdown-—Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —É–∑–ª–∞—Ö
        #    –ß—Ç–æ–±—ã "—Å—ã—Ä—ã–µ" _, *, [ ] –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ –ø—Ä–µ–≤—Ä–∞—â–∞–ª–∏—Å—å –≤ —Ä–∞–∑–º–µ—Ç–∫—É
        self._escape_text_nodes(soup)

        # 6. –£–º–Ω–∞—è —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤ –≤–æ–∫—Ä—É–≥ inline-—Ç–µ–≥–æ–≤ –≤ DOM.
        #    –í–º–µ—Å—Ç–æ regex-–ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞, –º—ã —Ä–∞–∑–¥–≤–∏–≥–∞–µ–º "—Å–ª–∏–ø—à–∏–µ—Å—è" —É–∑–ª—ã
        #    –Ω–∞ —É—Ä–æ–≤–Ω–µ HTML (—Ç–µ–∫—Å—Ç<b>bold</b> -> —Ç–µ–∫—Å—Ç <b>bold</b>).
        self._ensure_spacing(soup)

        return str(soup)

    @staticmethod
    def _ensure_spacing(soup):
        """–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –≤–æ–∫—Ä—É–≥ inline-—Ç–µ–≥–æ–≤ –≤ DOM.
        
        –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —É–∑–µ–ª "–ø—Ä–∏–ª–∏–ø" –∫ —Ç–µ–≥—É —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –≤—Å—Ç–∞–≤–ª—è–µ—Ç –º–∞—Ä–∫–µ—Ä.
        –ü—Ä–∏–º–µ—Ä: "word<b>bold</b>" -> "word@@@SP@@@<b>bold</b>"
        html2text —Å–æ—Ö—Ä–∞–Ω–∏—Ç —ç—Ç–æ –∫–∞–∫ "word@@@SP@@@**bold**".
        –ü–æ–∑–∂–µ –º–∞—Ä–∫–µ—Ä –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ –ø—Ä–æ–±–µ–ª.
        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ NBSP –∏–ª–∏ –æ–±—ã—á–Ω–æ–≥–æ –ø—Ä–æ–±–µ–ª–∞ –Ω–µ–Ω–∞–¥–µ–∂–Ω–æ, —Ç.–∫. html2text –º–æ–∂–µ—Ç –∏—Ö —Å—Ö–ª–æ–ø–Ω—É—Ç—å.
        """
        from bs4 import NavigableString, Tag
        
        # –ú–∞—Ä–∫–µ—Ä –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ–±–µ–ª–∞
        SPACER = '@@@SP@@@'
        
        # –¢–µ–≥–∏, –≤–æ–∫—Ä—É–≥ –∫–æ—Ç–æ—Ä—ã—Ö –Ω—É–∂–Ω—ã –ø—Ä–æ–±–µ–ª—ã (–µ—Å–ª–∏ –æ–Ω–∏ –≥—Ä–∞–Ω–∏—á–∞—Ç —Å —Ç–µ–∫—Å—Ç–æ–º)
        inline_tags = {'b', 'strong', 'em', 'i', 'a', 'code', 'span'}
        
        # –û–±—Ö–æ–¥–∏–º –≤—Å–µ —Ç–∞–∫–∏–µ —Ç–µ–≥–∏
        for tag in soup.find_all(list(inline_tags)):
            if tag.parent is None:
                continue
                
            # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª–µ–≤–∞ (prev_sibling) ---
            prev_node = tag.previous_sibling
            if isinstance(prev_node, NavigableString):
                text = str(prev_node)
                if text:
                    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ø—Ä–æ–±–µ–ª–æ–º -> –∑–∞–º–µ–Ω—è–µ–º –µ–≥–æ –Ω–∞ –º–∞—Ä–∫–µ—Ä
                    if text.endswith(' '):
                        new_text = text.rstrip(' ')
                        if new_text:
                            prev_node.replace_with(NavigableString(new_text))
                        else:
                            prev_node.extract()
                        tag.insert_before(NavigableString(SPACER))
                    
                    # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–±–µ–ª–∞, –Ω–æ –Ω—É–∂–µ–Ω (–±—É–∫–≤–∞/–ø—É–Ω–∫—Ç—É–∞—Ü–∏—è)
                    elif text[-1].isalnum() or text[-1] in '.,:;!?")':
                        tag.insert_before(NavigableString(SPACER))
            
            # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø—Ä–∞–≤–∞ (next_sibling) ---
            next_node = tag.next_sibling
            if isinstance(next_node, NavigableString):
                text = str(next_node)
                if text:
                    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –ø—Ä–æ–±–µ–ª–∞ -> –∑–∞–º–µ–Ω—è–µ–º
                    if text.startswith(' '):
                        new_text = text.lstrip(' ')
                        if new_text:
                            next_node.replace_with(NavigableString(new_text))
                        else:
                            next_node.extract()
                        tag.insert_after(NavigableString(SPACER))
                    
                    # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–±–µ–ª–∞, –Ω–æ –Ω—É–∂–µ–Ω
                    elif text[0].isalnum() or text[0] in '("':
                        tag.insert_after(NavigableString(SPACER))

    @staticmethod
    def _escape_text_nodes(soup):
        """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã Markdown –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —É–∑–ª–∞—Ö."""
        from bs4 import NavigableString
        
        replacements = {
            '_': '@@@US@@@',
            '*': '@@@AST@@@',
            '[': '@@@LBR@@@',
            ']': '@@@RBR@@@',
        }
        
        for text_node in soup.find_all(string=True):
            if text_node.parent and text_node.parent.name in ['script', 'style', 'title']:
                continue
            
            text = str(text_node)
            if not text:
                continue
                
            new_text = text
            for char, placeholder in replacements.items():
                if char in new_text:
                    new_text = new_text.replace(char, placeholder)
            
            if new_text != text:
                text_node.replace_with(NavigableString(new_text))

    @staticmethod
    def _merge_adjacent_em(soup, em_tags: set, bold_tags: set):
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–æ—Å–µ–¥–Ω–∏–µ <em>/<i> —Ç–µ–≥–∏ –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è.
        
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ª—É—á–∞–∏ –≤–∏–¥–∞:
          <em>–≤—ã</em> <b><em>–æ–±—è–∑–∞–Ω—ã</em></b> <em>—ç—Ç–æ</em>
        ‚Üí <em>–≤—ã <b>–æ–±—è–∑–∞–Ω—ã</b> —ç—Ç–æ</em>
        
        –ú–µ–∂–¥—É <em> –º–æ–≥—É—Ç –±—ã—Ç—å:
        - whitespace (NavigableString –∏–∑ –ø—Ä–æ–±–µ–ª–æ–≤)
        - <b>/<strong>, —Ü–µ–ª–∏–∫–æ–º –æ–±—ë—Ä–Ω—É—Ç—ã–µ –≤ <em> (<b><em>—Ç–µ–∫—Å—Ç</em></b>)
        """
        from bs4 import NavigableString, Tag
        
        def is_em(node):
            """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —É–∑–µ–ª —Ç–µ–≥–æ–º em/i."""
            return isinstance(node, Tag) and node.name in em_tags
        
        def is_bold_wrapped_em(node):
            """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —É–∑–µ–ª <b><em>—Ç–µ–∫—Å—Ç</em></b>."""
            if not isinstance(node, Tag) or node.name not in bold_tags:
                return False
            children = list(node.children)
            return len(children) == 1 and is_em(children[0])
        
        def is_whitespace(node):
            """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —É–∑–µ–ª –ø—Ä–æ–±–µ–ª—å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º."""
            return isinstance(node, NavigableString) and node.strip() == ''
        
        # –û–±—Ö–æ–¥–∏–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å em-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        # –ù–µ–ª—å–∑—è –∏—Ç–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é, —Ç.–∫. –¥–µ—Ä–µ–≤–æ –º—É—Ç–∏—Ä—É–µ—Ç ‚Äî —Å–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ä–æ–¥–∏—Ç–µ–ª–µ–π
        parents = set()
        for em in soup.find_all(list(em_tags)):
            if em.parent is not None:
                parents.add(id(em.parent))
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–≥–æ children
        for parent in list(soup.descendants):
            if not isinstance(parent, Tag) or id(parent) not in parents:
                continue
            
            # –°–æ–±–∏—Ä–∞–µ–º runs ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ—Å–µ–¥–Ω–∏—Ö em-—ç–ª–µ–º–µ–Ω—Ç–æ–≤
            children = list(parent.children)
            i = 0
            while i < len(children):
                # –ò—â–µ–º –Ω–∞—á–∞–ª–æ run: –ø–µ—Ä–≤—ã–π <em>
                if not is_em(children[i]):
                    i += 1
                    continue
                
                # –°–æ–±–∏—Ä–∞–µ–º run: <em>, whitespace, <b><em>...</em></b>, <em>, ...
                run_start = i
                run_nodes = [children[i]]
                j = i + 1
                while j < len(children):
                    node = children[j]
                    if is_em(node) or is_bold_wrapped_em(node):
                        run_nodes.append(node)
                        j += 1
                    elif is_whitespace(node):
                        # –ü—Ä–æ–±–µ–ª –º–µ–∂–¥—É em-—ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –≤ run
                        # –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞ –Ω–∏–º —Å–ª–µ–¥—É–µ—Ç –µ—â—ë em/bold-em
                        if j + 1 < len(children) and (is_em(children[j + 1]) or is_bold_wrapped_em(children[j + 1])):
                            run_nodes.append(node)
                            j += 1
                        else:
                            break
                    else:
                        break
                
                # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 em-—ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω–µ —Å—á–∏—Ç–∞—è whitespace) –¥–ª—è —Å–ª–∏—è–Ω–∏—è
                em_count = sum(1 for n in run_nodes if is_em(n) or is_bold_wrapped_em(n))
                if em_count < 2:
                    i = j
                    continue
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º run –≤ –æ–¥–∏–Ω <em>
                # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π <em> –∫–∞–∫ –±–∞–∑—É, –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤ –Ω–µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
                first_em = run_nodes[0]
                
                for node in run_nodes[1:]:
                    if is_whitespace(node):
                        # –ü—Ä–æ–±–µ–ª ‚Üí –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤–Ω—É—Ç—Ä—å first_em
                        ws = NavigableString(str(node))
                        node.extract()
                        first_em.append(ws)
                    elif is_em(node):
                        # <em>—Ç–µ–∫—Å—Ç</em> ‚Üí –ø–µ—Ä–µ–Ω–æ—Å–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ first_em
                        for child in list(node.children):
                            child.extract()
                            first_em.append(child)
                        node.extract()
                    elif is_bold_wrapped_em(node):
                        # <b><em>—Ç–µ–∫—Å—Ç</em></b> ‚Üí <b>—Ç–µ–∫—Å—Ç</b>, –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤ first_em
                        inner_em = list(node.children)[0]
                        inner_em.unwrap()  # —É–±–∏—Ä–∞–µ–º <em>, –æ—Å—Ç–∞–≤–ª—è—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ <b>
                        node.extract()
                        first_em.append(node)
                
                # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º children, —Ç.–∫. –¥–µ—Ä–µ–≤–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
                children = list(parent.children)
                # –ù–µ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É–µ–º i ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º —Å —Ç–æ–≥–æ –∂–µ –º–µ—Å—Ç–∞
                # (first_em –æ—Å—Ç–∞–ª—Å—è, –Ω–æ children –ø–µ—Ä–µ—Å–æ–±—Ä–∞–ª–∏—Å—å)
                i = children.index(first_em) + 1 if first_em in children else j

    @staticmethod
    def _first_navigable_string(tag):
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —É–∑–µ–ª (NavigableString) –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–∞."""
        from bs4 import NavigableString
        for desc in tag.descendants:
            if isinstance(desc, NavigableString) and desc.strip():
                return desc
        # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–µ–ø—É—Å—Ç—ã—Ö, –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π –ª—é–±–æ–π
        for desc in tag.descendants:
            if isinstance(desc, NavigableString):
                return desc
        return None

    @staticmethod
    def _last_navigable_string(tag):
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —É–∑–µ–ª (NavigableString) –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–∞."""
        from bs4 import NavigableString
        last = None
        for desc in tag.descendants:
            if isinstance(desc, NavigableString):
                last = desc
        # –ù–∞–º –Ω—É–∂–µ–Ω –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å —Ç–µ–∫—Å—Ç–æ–º, –∞ –µ—Å–ª–∏ –≤—Å–µ –ø—É—Å—Ç—ã–µ ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–π –ª—é–±–æ–π
        last_with_text = None
        for desc in tag.descendants:
            if isinstance(desc, NavigableString) and desc.strip():
                last_with_text = desc
        return last_with_text if last_with_text is not None else last

    def _to_markdown(self, post: Post, asset_map: dict[str, str]) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç HTML –≤ Markdown."""
        if not post.content_html:
            return ""

        # –ó–∞–º–µ–Ω—è–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã–µ
        html = post.content_html
        for original_url, local_filename in asset_map.items():
            html = html.replace(original_url, f"assets/{local_filename}")

        # –ó–∞–º–µ–Ω—è–µ–º iframe/embed –≤–∏–¥–µ–æ –Ω–∞ markdown-—Å—Å—ã–ª–∫–∏
        html = self._replace_video_embeds(html)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ HTML
        html = self._cleanup_html(html)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º HTML –≤ Markdown
        h2t = html2text.HTML2Text()
        h2t.ignore_links = False
        h2t.ignore_images = False
        h2t.body_width = 0  # –ë–µ–∑ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫
        h2t.unicode_snob = True

        markdown = h2t.handle(html)

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (–∏–∑ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ DOM)
        markdown = markdown.replace('@@@US@@@', r'\_')
        markdown = markdown.replace('@@@AST@@@', r'\*')
        markdown = markdown.replace('@@@LBR@@@', r'\[')
        markdown = markdown.replace('@@@RBR@@@', r'\]')
        # –ó–∞–º–µ–Ω—è–µ–º –º–∞—Ä–∫–µ—Ä—ã –ø—Ä–æ–±–µ–ª–æ–≤, –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –≤ DOM
        markdown = markdown.replace('@@@SP@@@', ' ')

        # –£–¥–∞–ª—è–µ–º bidi-–º–∞—Ä–∫–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –ª–æ–º–∞—é—Ç –ø—Ä–æ–±–µ–ª—ã —Ä—è–¥–æ–º —Å —Ç–µ–∫—Å—Ç–æ–º
        markdown = re.sub(r'[\u200e\u200f\u202a-\u202e\u2066-\u2069]', '', markdown)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        markdown = re.sub(r'[\u00a0\u202f]', ' ', markdown)

        # –°–∫–ª–µ–∏–≤–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ em/strong –≤ –∂–∏—Ä–Ω—ã–π –∫—É—Ä—Å–∏–≤
        # html2text —Å–æ–∑–¥–∞—ë—Ç ** _—Ç–µ–∫—Å—Ç_** –∏–ª–∏ _**—Ç–µ–∫—Å—Ç**_ –¥–ª—è <b><em>
        # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ø–µ—Ä–≤—ã–π regex —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç \s* (html2text –¥–ª—è <strong><em> –¥–∞—ë—Ç ** _text_**)
        # –í—Ç–æ—Ä–æ–π regex –±–µ–∑ \s* ‚Äî –∏–Ω–∞—á–µ –æ–Ω –∂–∞–¥–Ω–æ –ª–æ–≤–∏—Ç _–≤—ã_ ***–æ–±—è–∑–∞–Ω—ã*** _—ç—Ç–æ_
        markdown = re.sub(r'\*\*\s*_(.+?)_\s*\*\*', r'***\1***', markdown)
        markdown = re.sub(r'_\*\*(.+?)\*\*_', r'***\1***', markdown)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º 4+ –∑–≤—ë–∑–¥–æ—á–µ–∫ –¥–æ 3 (—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞ –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ —Å–ª–∏—è–Ω–∏—è)
        # ****—Ç–µ–∫—Å—Ç**** ‚Üí ***—Ç–µ–∫—Å—Ç***, *****—Ç–µ–∫—Å—Ç***** ‚Üí ***—Ç–µ–∫—Å—Ç***
        markdown = re.sub(r'\*{4,}(.+?)\*{4,}', r'***\1***', markdown)
        
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–Ω—É—Ç—Ä—å —Å—Å—ã–ª–æ–∫
        # [** _—Ç–µ–∫—Å—Ç_**](url) ‚Üí [***—Ç–µ–∫—Å—Ç***](url)
        markdown = re.sub(r'\[(\*{2,3})\s*(.+?)\s*(\*{2,3})\]\((.+?)\)', r'[\1\2\3](\4)', markdown)
        # ***[—Ç–µ–∫—Å—Ç](url)*** ‚Üí [***—Ç–µ–∫—Å—Ç***](url)
        markdown = re.sub(r'(\*{2,3})\[(.+?)\]\((.+?)\)\1', r'[\1\2\1](\3)', markdown)
        # _[—Ç–µ–∫—Å—Ç](url)_ ‚Üí [_—Ç–µ–∫—Å—Ç_](url)
        markdown = re.sub(r'_\[(.+?)\]\((.+?)\)_', r'[_\1_](\2)', markdown)

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ html2text —Ä—è–¥–æ–º —Å Unicode-–∫–∞–≤—ã—á–∫–∞–º–∏
        # –û—Ç–∫—Ä—ã–≤–∞—é—â–∏–µ: ¬´ ‚Äû " '
        markdown = re.sub(r'([\u00ab\u201e\u201c\u2018])\s+', r'\1', markdown)
        # –ó–∞–∫—Ä—ã–≤–∞—é—â–∏–µ: ¬ª " '
        markdown = re.sub(r'\s+([\u00bb\u201d\u2019])', r'\1', markdown)

        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è (.,:;!?)
        # –†–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è: –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, —Å—Å—ã–ª–æ–∫, –∫—É—Ä—Å–∏–≤–∞, –∂–∏—Ä–Ω–æ–≥–æ
        # [link](url) . -> [link](url).
        # word _._ -> word_._
        # word **.** -> word**.**
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º [ \t]+ –≤–º–µ—Å—Ç–æ \s+, —á—Ç–æ–±—ã –Ω–µ —É–¥–∞–ª—è—Ç—å –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        punct = r'[.,:;!?]'
        # 1. –û–±—ã—á–Ω–∞—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è
        markdown = re.sub(r'[ \t]+(' + punct + ')', r'\1', markdown)
        # 2. –ö—É—Ä—Å–∏–≤–Ω–∞—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è (_._)
        markdown = re.sub(r'[ \t]+(_' + punct + '_)', r'\1', markdown)
        # 3. –ñ–∏—Ä–Ω–∞—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è (**.**)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º [*][*] –≤–º–µ—Å—Ç–æ \*\*, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å SyntaxWarning
        markdown = re.sub(r'[ \t]+([*][*]' + punct + '[*][*])', r'\1', markdown)
        # 4. –ö—É—Ä—Å–∏–≤, –Ω–∞—á–∏–Ω–∞—é—â–∏–π—Å—è —Å–æ –∑–Ω–∞–∫–∞ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è (_, text_)
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –Ω–∏–º: word _, -> word_,
        markdown = re.sub(r'[ \t]+(_' + punct + ')', r'\1', markdown)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã html2text –≤–Ω—É—Ç—Ä–∏ —Å—Å—ã–ª–æ–∫: [ _—Ç–µ–∫—Å—Ç_ ] -> [_—Ç–µ–∫—Å—Ç_]
        markdown = re.sub(r'\[\s+_', r'[_', markdown)
        markdown = re.sub(r'_\s+\]', r'_]', markdown)

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –±–µ—Ä—ë—Ç—Å—è –∏–∑ frontmatter (Hugo), –Ω–µ –¥—É–±–ª–∏—Ä—É–µ–º –µ–≥–æ –≤ body.
        return markdown
